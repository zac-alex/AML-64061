{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Leveraging a pretrained model\n",
        "Feature extraction with a pretrained model\n",
        "Instantiating the VGG16 convolutional base"
      ],
      "metadata": {
        "id": "YuH72QsV28T-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYphgJIOFEHt",
        "outputId": "18730d93-23aa-4227-c048-e64a3c913b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of the model"
      ],
      "metadata": {
        "id": "JO1iq_Ag3DZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33PNI-TDFMZZ",
        "outputId": "aee737e6-6522-4a07-e676-0dba63b7f246"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading the dataset"
      ],
      "metadata": {
        "id": "EHjnIVMe3LHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip -qq dogs-vs-cats.zip\n",
        "!unzip -qq train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "_KMfSEm9uvzs",
        "outputId": "00e33694-cf2e-4e50-d049-8920f97b37fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6eba1241-78ac-429e-9c56-5d68a9736b19\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6eba1241-78ac-429e-9c56-5d68a9736b19\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 808M/812M [00:02<00:00, 307MB/s]\n",
            "100% 812M/812M [00:02<00:00, 309MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating directory and splitting dataset into train,validation and test sets"
      ],
      "metadata": {
        "id": "ceIx6rnW3QSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train5\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation5\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test5\", start_index=1500, end_index=2000)"
      ],
      "metadata": {
        "id": "v76fqnJhupSK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Re-shaping the images"
      ],
      "metadata": {
        "id": "UCLabHta3ann"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train5\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation5\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test5\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu5ufijkug_h",
        "outputId": "6d636418-4397-4def-9808-1893cd19f38c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the VGG16 features and corresponding labels"
      ],
      "metadata": {
        "id": "Jt2jRV843gJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkrz8Fy0FTQY",
        "outputId": "66deca6d-23e8-46b8-907b-450795e99a4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg8c5bb1Fbvw",
        "outputId": "9c5fcf28-22cd-4136-9c47-569cf7db2dd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining and training the densely connected classifier"
      ],
      "metadata": {
        "id": "gABMEV-s3i_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=6,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyfdctX0FeOe",
        "outputId": "9c92c271-613e-482a-9b88-1d8e94694f5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "63/63 [==============================] - 3s 8ms/step - loss: 19.1714 - accuracy: 0.9245 - val_loss: 3.5684 - val_accuracy: 0.9650\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 3.8003 - accuracy: 0.9700 - val_loss: 5.1082 - val_accuracy: 0.9610\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.7193 - accuracy: 0.9865 - val_loss: 5.0248 - val_accuracy: 0.9630\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.1619 - accuracy: 0.9885 - val_loss: 4.0655 - val_accuracy: 0.9750\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8941 - accuracy: 0.9935 - val_loss: 4.9013 - val_accuracy: 0.9720\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.2454 - accuracy: 0.9935 - val_loss: 4.9271 - val_accuracy: 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the results"
      ],
      "metadata": {
        "id": "WzoL8nmD3mVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "bay_eEdqFpaH",
        "outputId": "f9388712-34a7-4c68-9240-f0d3ae572f72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqwUlEQVR4nO3deXxV1bn/8c9DmEQQNCACQYKCIophiHDFAXBosfrDghOItui1WNR6tVe5KFa9WG610jpc7YB1LhatrV5tUauIQ0urRCCoDAoIGhCMIMggQ8jz+2PthJOQ4QAnOcnO9/16ndfZw9r7PPsEnr3O2muvbe6OiIjEV6N0ByAiIjVLiV5EJOaU6EVEYk6JXkQk5pToRURiToleRCTmlOgbIDN7ycy+n+qy6WRmK8zsjBrYr5tZt2j6N2b2k2TK7sPnjDazv+1rnCJVMfWjrx/MbHPCbAtgO7Armr/S3afVflR1h5mtAK5w99dSvF8Hurv70lSVNbNs4BOgibsXpSRQkSo0TncAkhx3b1kyXVVSM7PGSh5SV+jfY92gppt6zswGm1mBmf2Xma0BHjWzg83sL2ZWaGZfRdNZCdu8YWZXRNNjzOzvZjYlKvuJmZ21j2W7mtlbZrbJzF4zswfN7PeVxJ1MjHeY2T+i/f3NzNomrL/UzFaa2Tozm1jF9zPAzNaYWUbCsuFmtiCa7m9m/zSzDWb2uZk9YGZNK9nXY2b204T5G6NtVpvZ5eXKnm1m88zsazP7zMxuT1j9VvS+wcw2m9mJJd9twvYDzWyOmW2M3gcm+93s5fd8iJk9Gh3DV2b2fMK6c81sfnQMy8xsaLS8TDOZmd1e8nc2s+yoCevfzexT4PVo+R+jv8PG6N/IsQnbH2Bmv4j+nhujf2MHmNlfzexH5Y5ngZkNr+hYpXJK9PFwGHAI0AUYS/i7PhrNHw58AzxQxfYDgCVAW+DnwMNmZvtQ9ingXSATuB24tIrPTCbGi4HLgEOBpsANAGbWE/h1tP+O0edlUQF3fwfYApxWbr9PRdO7gOuj4zkROB24qoq4iWIYGsVzJtAdKH99YAvwPaANcDYwzsy+G607NXpv4+4t3f2f5fZ9CPBX4P7o2H4J/NXMMssdwx7fTQWq+56fJDQFHhvt654ohv7AE8CN0TGcCqyo5DMqMgg4Bvh2NP8S4Xs6FJgLJDY1TgH6AQMJ/47HA8XA48AlJYXMLAfoRPhuZG+4u1717EX4D3dGND0Y2AE0r6J8b+CrhPk3CE0/AGOApQnrWgAOHLY3ZQlJpAhokbD+98DvkzymimK8JWH+KuDlaPpWYHrCugOj7+CMSvb9U+CRaLoVIQl3qaTsdcBzCfMOdIumHwN+Gk0/AtyZUO6oxLIV7Pde4J5oOjsq2zhh/Rjg79H0pcC75bb/JzCmuu9mb75noAMhoR5cQbnflsRb1b+/aP72kr9zwrEdUUUMbaIyrQknom+AnArKNQe+Ilz3gHBC+FVN/J+K+0s1+ngodPdtJTNm1sLMfhv9FP6a0FTQJrH5opw1JRPuvjWabLmXZTsC6xOWAXxWWcBJxrgmYXprQkwdE/ft7luAdZV9FqH2PsLMmgEjgLnuvjKK46ioOWNNFMf/EGr31SkTA7Cy3PENMLNZUZPJRuCHSe63ZN8ryy1bSajNlqjsuymjmu+5M+Fv9lUFm3YGliUZb0VKvxszyzCzO6Pmn6/Z/cugbfRqXtFnRf+mnwYuMbNGwCjCLxDZS0r08VC+69R/AkcDA9z9IHY3FVTWHJMKnwOHmFmLhGWdqyi/PzF+nrjv6DMzKyvs7gsJifIsyjbbQGgCWkyoNR4E3LwvMRB+0SR6CngB6OzurYHfJOy3uq5uqwlNLYkOB1YlEVd5VX3PnxH+Zm0q2O4z4MhK9rmF8GuuxGEVlEk8xouBcwnNW60Jtf6SGL4EtlXxWY8DowlNalu9XDOXJEeJPp5aEX4Ob4jae2+r6Q+Mash5wO1m1tTMTgT+Xw3F+CxwjpmdHF04nUT1/5afAv6DkOj+WC6Or4HNZtYDGJdkDM8AY8ysZ3SiKR9/K0JteVvU3n1xwrpCQpPJEZXsewZwlJldbGaNzewioCfwlyRjKx9Hhd+zu39OaDv/VXTRtomZlZwIHgYuM7PTzayRmXWKvh+A+cDIqHwucH4SMWwn/OpqQfjVVBJDMaEZ7Jdm1jGq/Z8Y/foiSuzFwC9QbX6fKdHH073AAYTa0r+Al2vpc0cTLmiuI7SLP034D16Re9nHGN39Q+BqQvL+nNCOW1DNZn8gXCB83d2/TFh+AyEJbwIeimJOJoaXomN4HVgavSe6CphkZpsI1xSeSdh2KzAZ+IeF3j7/Vm7f64BzCLXxdYSLk+eUiztZ91L193wpsJPwq+YLwjUK3P1dwsXee4CNwJvs/pXxE0IN/Cvgvyn7C6kiTxB+Ua0CFkZxJLoBeB+YA6wH7qJsbnoC6EW45iP7QDdMSY0xs6eBxe5e478oJL7M7HvAWHc/Od2x1Feq0UvKmNkJZnZk9FN/KKFd9vk0hyX1WNQsdhUwNd2x1GdK9JJKhxG6/m0m9AEf5+7z0hqR1Ftm9m3C9Yy1VN88JFVQ042ISMypRi8iEnN1blCztm3benZ2drrDEBGpV957770v3b1dRevqXKLPzs4mLy8v3WGIiNQrZlb+bupSaroREYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EalTpk2D7Gxo1Ci8T2sAj72v6WOuc90rRaThmjYNxo6FrdHja1auDPMAo0enL66aVBvHXOeGQMjNzXX1oxdpmLKzQ6Irr0sXWLGitqOpHak6ZjN7z91zK1qnphsRqTM+/XTvlsdBbRyzEr2I1BmHl38gYzXL46A2jlmJXkTqjMmToUWLsstatAjL46o2jlmJXkTqjNGjYerU0D5tFt6nTo3vhVionWPWxVgRkRjQxVgRkQZMiV5EJOaSSvRmNtTMlpjZUjObUMH6LmY208wWmNkbZpaVsO4uM/sgel2UyuBFRKR61SZ6M8sAHgTOAnoCo8ysZ7liU4An3P14YBLws2jbs4G+QG9gAHCDmR2UsuhFRKRaydTo+wNL3X25u+8ApgPnlivTE3g9mp6VsL4n8Ja7F7n7FmABMHT/wxYRkWQlk+g7AZ8lzBdEyxLlAyOi6eFAKzPLjJYPNbMWZtYWGAJ0Lv8BZjbWzPLMLK+wsHBvj0FERKqQqouxNwCDzGweMAhYBexy978BM4DZwB+AfwK7ym/s7lPdPdfdc9u1q/DZtiIiso+SSfSrKFsLz4qWlXL31e4+wt37ABOjZRui98nu3tvdzwQM+CgVgYs0BA1xyF5JvWQS/Rygu5l1NbOmwEjghcQCZtbWzEr2dRPwSLQ8I2rCwcyOB44H/paq4EXirGT42pUrwX338LVK9rK3qk307l4EXAO8AiwCnnH3D81skpkNi4oNBpaY2UdAe6BklIYmwNtmthCYClwS7U9EqjFx4u4xykts3RqWi+wNDYEgUkc1ahRq8uWZQXFx7ccjdZuGQBCphxrikL1SM5Topd5oaBcmG+KQvVIzlOilXmiIFyYb4pC9UjPURi/1QkN8lqjI3lAbvdR7DfFZoiKpokQv9YIuTIrsOyV6qRd0YVJk3ynRS72gC5Mi+65xugMQSdbo0UrsIvtCNXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYSyrRm9lQM1tiZkvNbEIF67uY2UwzW2Bmb5hZVsK6n5vZh2a2yMzuNzNL5QGIiEjVqk30ZpYBPAicBfQERplZz3LFpgBPuPvxwCTgZ9G2A4GTgOOB44ATgEEpi15ERKqVTI2+P7DU3Ze7+w5gOnBuuTI9gdej6VkJ6x1oDjQFmgFNgLX7G7SIiCQvmUTfCfgsYb4gWpYoHxgRTQ8HWplZprv/k5D4P49er7j7ovIfYGZjzSzPzPIKCwv39hhERKQKqboYewMwyMzmEZpmVgG7zKwbcAyQRTg5nGZmp5Tf2N2nunuuu+e2a9cuRSGJiAgk9+CRVUDnhPmsaFkpd19NVKM3s5bAee6+wcx+APzL3TdH614CTgTeTkHsIiKShGRq9HOA7mbW1cyaAiOBFxILmFlbMyvZ103AI9H0p4SafmMza0Ko7e/RdCMiIjWn2kTv7kXANcArhCT9jLt/aGaTzGxYVGwwsMTMPgLaAyWPbH4WWAa8T2jHz3f3F1N7CCIiUhVz93THUEZubq7n5eWlOwwRkXrFzN5z99yK1unOWBGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmEtmCAQRSaP8fHjlFTj8cOjWLbzatEl3VFKfKNGL1FGffw633AKPPgrl72vMzNyd9Lt1g+7dd08fcgjo8T6SSIlepI755hv4xS/gzjthxw748Y/hP/8T1q+HpUvD6+OPw/vf/w5PPVX2RNCmTcUngG7doF07nQQaIiV6kTqiuBj+8Ae46Sb47DMYMQJ+/nM48siwvkMHOPbYPbfbvh0++aTsCWDpUnj3XXjmmbDfEq1aVX4SOOwwnQTiSolepA74xz9Czf3dd6FfP/j97+HUU5Pbtlkz6NEjvMrbsQNWrtzzJDB/Pjz3HBQV7S574IHhpFL+BNCtG3TsCI3UdaPeUqIXSaNPPoEJE0LNu2NHePxxuOSS1CXVpk1D4u7eHc46q+y6oiL49NM9TwIffggvvhhOEiWaN6/8JJCVBRkZqYlXaoYSvUgafP01/M//wL33hqR+221w442hVl1bGjeGI44Ir299q+y6XbugoGDPk8DHH8PLL8O2bbvLNm0aTgLlTwDduoWeQo2VZdJOfwKRWlRUBA8/DD/5CRQWwve+FxJ+p/JPYU6zjAzo0iW8Tj+97LriYli9uuwJoOQ1cyZs3bq7bJMm0LVrxSeB7OywXmqeEr1ILXn11dAO/8EHcMopMGMG5FY4enjd1qhRaK7JyoIhQ8quc4c1ayo+Cbz1FmzevLtsRkZI9hWdBLp2DdceJDWU6EVq2KJFcMMNIbEfcQT86U8wfHg8e7iYhd5BHTrseTHZHb74Ys8TwNKl8K9/wcaNu8s2ahSuWXToEHoDVfVq0aJ2j7E+UqIXqSFffgm33w6/+U1oe7/7bvjRjxpuTdUM2rcPr5NOKrvOHdatK5v8V6yAtWtDV9M5c8JJIrGraImDDqr+ZHDYYeEegoZ6vaCBHrZIzdm+HR54AO64IzRVXHllSPjt2qU7srrLDNq2Da9/+7eKy+zaFU6en38emocqepUMF5H466BEo0bhb5DMSaF163j94koq0ZvZUOA+IAP4nbvfWW59F+ARoB2wHrjE3QvMbAhwT0LRHsBId38+BbGL1CnuoW/6+PGwbFnozjhlCvTsme7I4iEjY/cvgup88034NbBmTeUnhkWLwntiN9ISzZqFhF9d01H79qHraV1X7cPBzSwD+Ag4EygA5gCj3H1hQpk/An9x98fN7DTgMne/tNx+DgGWAlnuvpVK6OHgyZs2DSZODH2hDz8cJk+G0aPTHVXDNHduuND65pvh7tVf/AK+/e10RyXVcYcNG6o+IZS8Cgsr3kebNsldS2jbtmZvOqvq4eDJ1Oj7A0vdfXm0s+nAucDChDI9gR9H07OA5yvYz/nAS1UleUnetGkwduzurmwrV4Z5ULKvTatXw803wxNPhP/Iv/41XHFFw20Lrm/M4OCDw+uYY6ouu3NnSPZVnRTmzAnvib2LSmRkwKGHVv1LISsr9DhKtWT+OXYCPkuYLwAGlCuTD4wgNO8MB1qZWaa7r0soMxL45X7EKgkmTizbXxnC/MSJSvS1YcuWUGu/667QN/7GG0PCb9063ZFJTWnSJPQE6tix+rKbN4emo+quJ6xdW3YYihNOCMNgpFqq6h03AA+Y2RjgLWAVsKtkpZl1AHoBr1S0sZmNBcYCHH744SkKKd4+/XTvlktqFBeHcWhuvhlWrYILLgjJviZqYVJ/tWwZXiUD0lWmuDiMSlqS/GtqKIlkEv0qoHPCfFa0rJS7rybU6DGzlsB57r4hociFwHPuvrOiD3D3qcBUCG30yQbfkB1+eGiuqWi51Iy33w7t8Hl54Uan6dPh5JPTHZXUZ40a7e5tdNxxNfg5SZSZA3Q3s65m1pTQBPNCYgEza2tmJfu6idADJ9Eo4A/7G6zsNnnynjeKtGgRlktqLV8O558fbgBaswaefBLeeUdJXuqPahO9uxcB1xCaXRYBz7j7h2Y2ycyGRcUGA0vM7COgPVCabswsm/CL4M3Uht6wjR4NU6eGsUjMwvvUqWqfT6WNG0Pb+zHHwEsvwaRJsGRJakeXFKkN1XavrG3qXinpVlQEDz0Et94a7tYcMwZ++tPkLsKJpEtV3StVLxFJ8PLLkJMDV10V+sPn5cEjjyjJS/2mRC9CeNjGWWeF144d4Q7XWbOgb990Ryay/5TopUErLIRx4+D448MIir/8ZUj63/1uvMY6kYZN9+9Jg7R9O9x/f2h737IFrr46POUpMzPdkYmknhK9NCjuYTz48ePD81rPOScMH1zRg7VF4kJNN9JgzJkT+sJfcEG4a/HVV8NDsJXkJe6U6CX2CgrCs1n794ePPgr3G8ybB2ecke7IRGqHmm4ktrZsgZ//PDTNFBfDTTfBhAnhiUQiDUlsEv3WrdC9O/TqBX36QO/e4dWtW80NFCR1U3FxGDb45pvD6IEjR8Kdd4a7h0Uaotgk+s2b4Vvfgvnzw/CxO6Ph01q0CF3nEpP/ccfpgcJx9eabcP31oWlmwIBw4fXEE9MdlUh6xXIIhB07wmPC5s0Lib/kVfIcyUaN4Oijyyb/3r31TM/6bOnS0JPmueegc+cwdPDIkeoLLw3H/j5hqt5p2jTcxp6Ts3uZexjWNzH5//3v8NRTu8t07BgSfuIJ4IgjNIBVXfbVV6Ev/P/+b3jO5+TJoUZ/wAHpjkyk7ohloq+IGWRnh9fw4buXr18fnvSSeAJ45ZXwxHkI3fBycsom/2OPrR8PBI6znTvht7+F228Pf8N//3e4447wODYRKSuWTTf7a9s2WLiwbPLPz4dNm8L6jIwwdG1i8s/J0V2VtWHz5jAGzfjxsHgxnHZaGLYg8debSEPU4Jpu9lfz5mEwq8QBrYqLw52Uicn/9dfDQyhKdO68Z7t/drbaiauzcyd88cXux6lV9ZzNLVvCNkcdBS+8EO5s1fcrUjXV6PdTYeGeTT+LF4cTA4SHRScm/t69oWfPcB0hztxD+3kyyfvLLyvex8EHh6aYww6DDh12T2dnh0HHmjSpzSMSqduqqtEr0deAb76BDz7Ys+ln69awvkmT0M6fmPxzcqBNm3RFnLytW8OT66tL3mvW7O7imqh5890Ju3wCT3y1bx8uropIcpTo64Bdu2DZsj27fK5Zs7tMdvaeTT+dO9d808SuXeGXSXWJe80a+PrrPbc3g0MPTS6BH3SQmlpEaoISfR22Zk3ZxD9/fhiPpeTPcsghezb99OhRfbOFe0jKySTvwsLdTU2JDjooueTdti001tUekbRSoq9ntmyB998vW/tfsCD0BoLQpHHccSHpH3NM6IlSUQIvKZ+oSZM9E3VFCbx9e909LFKf7HeiN7OhwH1ABvA7d7+z3PouwCNAO2A9cIm7F0TrDgd+B3QGHPiOu6+o7LOU6CtWVAQff1w2+c+bt/tCZtu2ySXwgw9W04lIHO1XojezDOAj4EygAJgDjHL3hQll/gj8xd0fN7PTgMvc/dJo3RvAZHd/1cxaAsXuvrWyz1OiT15Jz5ZWrdQDRaShqyrRJ3Nzf39gqbsvd/cdwHTg3HJlegKvR9OzStabWU+gsbu/CuDum6tK8rJ3zEIbvpK8iFQlmUTfCfgsYb4gWpYoHxgRTQ8HWplZJnAUsMHM/mxm88zs7ugXQhlmNtbM8swsr7CwcO+PQkREKpWq4bpuAAaZ2TxgELAK2EW48/aUaP0JwBHAmPIbu/tUd89199x2GkJSRCSlkkn0qwgXUktkRctKuftqdx/h7n2AidGyDYTa//yo2acIeB7oi4iI1JpkEv0coLuZdTWzpsBI4IXEAmbW1sxK9nUToQdOybZtzKykmn4asBAREak11Sb6qCZ+DfAKsAh4xt0/NLNJZjYsKjYYWGJmHwHtgcnRtrsIzTYzzex9wICHUn4UIiJSKd0wJSISA/vbvVJEROoxJXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhLKtGb2VAzW2JmS81sQgXru5jZTDNbYGZvmFlWwrpdZjY/er2QyuBFRKR6jasrYGYZwIPAmUABMMfMXnD3hQnFpgBPuPvjZnYa8DPg0mjdN+7eO7Vhi4hIspKp0fcHlrr7cnffAUwHzi1XpifwejQ9q4L1IiKSJskk+k7AZwnzBdGyRPnAiGh6ONDKzDKj+eZmlmdm/zKz71b0AWY2NiqTV1hYmHz0IiJSrVRdjL0BGGRm84BBwCpgV7Sui7vnAhcD95rZkeU3dvep7p7r7rnt2rVLUUgiIgJJtNETknbnhPmsaFkpd19NVKM3s5bAee6+IVq3KnpfbmZvAH2AZfsbuIiIJCeZGv0coLuZdTWzpsBIoEzvGTNra2Yl+7oJeCRafrCZNSspA5wEJF7EFRGRGlZtonf3IuAa4BVgEfCMu39oZpPMbFhUbDCwxMw+AtoDk6PlxwB5ZpZPuEh7Z7neOiIiUsPM3dMdQxm5ubmel5eX7jBEROoVM3svuh66B90ZKyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0klejMbamZLzGypmU2oYH0XM5tpZgvM7A0zyyq3/iAzKzCzB1IVuIiIJKfaRG9mGcCDwFlAT2CUmfUsV2wK8IS7Hw9MAn5Wbv0dwFv7H66IiOytZGr0/YGl7r7c3XcA04Fzy5XpCbweTc9KXG9m/YD2wN/2P1wREdlbyST6TsBnCfMF0bJE+cCIaHo40MrMMs2sEfAL4Ib9DVRERPZNqi7G3gAMMrN5wCBgFbALuAqY4e4FVW1sZmPNLM/M8goLC1MUkoiIADROoswqoHPCfFa0rJS7ryaq0ZtZS+A8d99gZicCp5jZVUBLoKmZbXb3CeW2nwpMBcjNzfV9PRgREdlTMol+DtDdzLoSEvxI4OLEAmbWFljv7sXATcAjAO4+OqHMGCC3fJIXEZGaVW3TjbsXAdcArwCLgGfc/UMzm2Rmw6Jig4ElZvYR4cLr5BqKV0RE9pK5162WktzcXM/Ly0t3GCIi9YqZvefuuRWt052xIiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIxp0QvIhJzSvQiIjGnRC8iEnNK9CIiMZfM6JUikiY7d+6koKCAbdu2pTsUqSOaN29OVlYWTZo0SXobJXqROqygoIBWrVqRnZ2NmaU7HEkzd2fdunUUFBTQtWvXpLdT041IHbZt2zYyMzOV5AUAMyMzM3Ovf+Ep0YvUcUrykmhf/j0o0YuIxJwSvUiMTJsG2dnQqFF4nzZt//a3bt06evfuTe/evTnssMPo1KlT6fyOHTuq3DYvL49rr7222s8YOHDg/gUp1dLFWJGYmDYNxo6FrVvD/MqVYR5g9OjKt6tKZmYm8+fPB+D222+nZcuW3HDDDaXri4qKaNy44jSSm5tLbm6FDzwqY/bs2fsWXBrt2rWLjIyMdIeRNNXoRWJi4sTdSb7E1q1heSqNGTOGH/7whwwYMIDx48fz7rvvcuKJJ9KnTx8GDhzIkiVLAHjjjTc455xzgHCSuPzyyxk8eDBHHHEE999/f+n+WrZsWVp+8ODBnH/++fTo0YPRo0dT8qjTGTNm0KNHD/r168e1115but9EK1as4JRTTqFv37707du3zAnkrrvuolevXuTk5DBhwgQAli5dyhlnnEFOTg59+/Zl2bJlZWIGuOaaa3jssccAyM7O5r/+67/o27cvf/zjH3nooYc44YQTyMnJ4bzzzmNr9OWvXbuW4cOHk5OTQ05ODrNnz+bWW2/l3nvvLd3vxIkTue+++/b3T5E01ehFYuLTT/du+f4oKChg9uzZZGRk8PXXX/P222/TuHFjXnvtNW6++Wb+9Kc/7bHN4sWLmTVrFps2beLoo49m3Lhxe/QFnzdvHh9++CEdO3bkpJNO4h//+Ae5ublceeWVvPXWW3Tt2pVRo0ZVGNOhhx7Kq6++SvPmzfn4448ZNWoUeXl5vPTSS/zf//0f77zzDi1atGD9+vUAjB49mgkTJjB8+HC2bdtGcXExn332WZXHnZmZydy5c4HQrPWDH/wAgFtuuYWHH36YH/3oR1x77bUMGjSI5557jl27drF582Y6duzIiBEjuO666yguLmb69Om8++67e/2976ukEr2ZDQXuAzKA37n7neXWdwEeAdoB64FL3L0gWv4c4ZdDE+B/3f03KYxfRCKHHx6aaypanmoXXHBBadPFxo0b+f73v8/HH3+MmbFz584Ktzn77LNp1qwZzZo149BDD2Xt2rVkZWWVKdO/f//SZb1792bFihW0bNmSI444orTf+KhRo5g6deoe+9+5cyfXXHMN8+fPJyMjg48++giA1157jcsuu4wWLVoAcMghh7Bp0yZWrVrF8OHDgXATUjIuuuii0ukPPviAW265hQ0bNrB582a+/e1vA/D666/zxBNPAJCRkUHr1q1p3bo1mZmZzJs3j7Vr19KnTx8yMzOT+sxUqLbpxswygAeBs4CewCgz61mu2BTgCXc/HpgE/Cxa/jlworv3BgYAE8ysY4piF5EEkydDlMtKtWgRlqfagQceWDr9k5/8hCFDhvDBBx/w4osvVtrHu1mzZqXTGRkZFBUV7VOZytxzzz20b9+e/Px88vLyqr1YXJHGjRtTXFxcOl/+WBKPe8yYMTzwwAO8//773HbbbdX2bb/iiit47LHHePTRR7n88sv3Orb9kUwbfX9gqbsvd/cdwHTg3HJlegKvR9OzSta7+w533x4tb5bk54nIPhg9GqZOhS5dwCy8T5267xdik7Vx40Y6deoEUNqenUpHH300y5cvZ8WKFQA8/fTTlcbRoUMHGjVqxJNPPsmuXbsAOPPMM3n00UdL29DXr19Pq1atyMrK4vnnnwdg+/btbN26lS5durBw4UK2b9/Ohg0bmDlzZqVxbdq0iQ4dOrBz506mJXRvOv300/n1r38NhIu2GzduBGD48OG8/PLLzJkzp7T2X1uSSbydgMSGq4JoWaJ8YEQ0PRxoZWaZAGbW2cwWRPu4y91Xl/8AMxtrZnlmlldYWLi3xyAikdGjYcUKKC4O7zWd5AHGjx/PTTfdRJ8+ffaqBp6sAw44gF/96lcMHTqUfv360apVK1q3br1HuauuuorHH3+cnJwcFi9eXFr7Hjp0KMOGDSM3N5fevXszZcoUAJ588knuv/9+jj/+eAYOHMiaNWvo3LkzF154IccddxwXXnghffr0qTSuO+64gwEDBnDSSSfRo0eP0uX33Xcfs2bNolevXvTr14+FCxcC0LRpU4YMGcKFF15Y6z12rOSqdqUFzM4Hhrr7FdH8pcAAd78moUxH4AGgK/AWcB5wnLtvKFfmeeD/ufvayj4vNzfX8/Ly9vV4RGJl0aJFHHPMMekOI+02b95My5YtcXeuvvpqunfvzvXXX5/usPZKcXFxaY+d7t2779e+Kvp3YWbvuXuF/VmTqdGvAjonzGdFy0q5+2p3H+HufYCJ0bIN5csAHwCnJPGZIiKlHnroIXr37s2xxx7Lxo0bufLKK9Md0l5ZuHAh3bp14/TTT9/vJL8vkul1MwfobmZdCQl+JHBxYgEzawusd/di4CZCDxzMLAtY5+7fmNnBwMnAPSmMX0QagOuvv77e1eAT9ezZk+XLl6ft86ut0bt7EXAN8AqwCHjG3T80s0lmNiwqNhhYYmYfAe2Bkuv8xwDvmFk+8CYwxd3fT/ExiIhIFZLqR+/uM4AZ5ZbdmjD9LPBsBdu9Chy/nzGKiMh+UHdHEZGYU6IXEYk5JXoRqdSQIUN45ZVXyiy79957GTduXKXbDB48mJIu0t/5znfYsGHDHmVuv/320v7slXn++edL+6AD3Hrrrbz22mt7Eb2UUKIXkUqNGjWK6dOnl1k2ffr0SgcWK2/GjBm0adNmnz67fKKfNGkSZ5xxxj7tK11K7s5NNyV6kXriuutg8ODUvq67rurPPP/88/nrX/9aOm7MihUrWL16Naeccgrjxo0jNzeXY489lttuu63C7bOzs/nyyy8BmDx5MkcddRQnn3xy6VDGQIXD/c6ePZsXXniBG2+8kd69e7Ns2TLGjBnDs8+GPh8zZ86kT58+9OrVi8svv5zt27eXft5tt91G37596dWrF4sXL94jpoY4nLESvYhU6pBDDqF///689NJLQKjNX3jhhZgZkydPJi8vjwULFvDmm2+yYMGCSvfz3nvvMX36dObPn8+MGTOYM2dO6boRI0YwZ84c8vPzOeaYY3j44YcZOHAgw4YN4+6772b+/PkceeSRpeW3bdvGmDFjePrpp3n//fcpKioqHVsGoG3btsydO5dx48ZV2DxUMpzx3Llzefrpp0ufgpU4nHF+fj7jx48HwnDGV199Nfn5+cyePZsOHTpU+72VDGc8cuTICo8PKB3OOD8/n7lz53Lsscdy+eWXl458WTKc8SWXXFLt51VH49GL1BMJFb1aVdJ8c+655zJ9+vTSRPXMM88wdepUioqK+Pzzz1m4cCHHH19xb+q3336b4cOHlw4VPGzYsNJ1lQ33W5klS5bQtWtXjjrqKAC+//3v8+CDD3Jd9PNkxIgw7Fa/fv3485//vMf2DXE449jU6FP9rEwRCc4991xmzpzJ3Llz2bp1K/369eOTTz5hypQpzJw5kwULFnD22WdXO0xvZfZ2uN/qlAx1XNkwxw1xOONYJPqSZ2WuXAnuu5+VqWQvsv9atmzJkCFDuPzyy0svwn799dcceOCBtG7dmrVr15Y27VTm1FNP5fnnn+ebb75h06ZNvPjii6XrKhvut1WrVmzatGmPfR199NGsWLGCpUuXAmEUykGDBiV9PA1xOONYJPraelamSEM1atQo8vPzSxN9Tk4Offr0oUePHlx88cWcdNJJVW7ft29fLrroInJycjjrrLM44YQTStdVNtzvyJEjufvuu+nTpw/Lli0rXd68eXMeffRRLrjgAnr16kWjRo344Q9/mPSxNMThjKsdpri27cswxY0ahZp8eWZhXG6R+krDFDc8yQxnXBPDFNd5lT0TsyaelSkiUlNqajjjWPS6mTw5tMknNt/U1LMyRURqSk0NZxyLGn26npUpUhvqWvOqpNe+/HuIRY0eQlJXYpe4ad68OevWrSMzMxMzS3c4kmbuzrp165Luz18iNoleJI6ysrIoKCigsLAw3aFIHdG8eXOysrL2ahslepE6rEmTJnTt2jXdYUg9F4s2ehERqZwSvYhIzCnRi4jEXJ27M9bMCoGV+7GLtsCXKQqnvmhox9zQjhd0zA3F/hxzF3dvV9GKOpfo95eZ5VV2G3BcNbRjbmjHCzrmhqKmjllNNyIiMadELyISc3FM9FPTHUAaNLRjbmjHCzrmhqJGjjl2bfQiIlJWHGv0IiKSQIleRCTmYpPozewRM/vCzD5Idyy1wcw6m9ksM1toZh+a2X+kO6aaZmbNzexdM8uPjvm/0x1TbTGzDDObZ2Z/SXcstcHMVpjZ+2Y238z27pFz9ZSZtTGzZ81ssZktMrMTU7bvuLTRm9mpwGbgCXc/Lt3x1DQz6wB0cPe5ZtYKeA/4rrsvTHNoNcbCOL0HuvtmM2sC/B34D3f/V5pDq3Fm9mMgFzjI3c9Jdzw1zcxWALnu3mBumDKzx4G33f13ZtYUaOHuG1Kx79jU6N39LWB9uuOoLe7+ubvPjaY3AYuATumNqmZ5sDmabRK94lFTqYKZZQFnA79LdyxSM8ysNXAq8DCAu+9IVZKHGCX6hszMsoE+wDtpDqXGRU0Y84EvgFfdPfbHDNwLjAca0qPuHfibmb1nZmPTHUwt6AoUAo9GTXS/M7MDU7VzJfp6zsxaAn8CrnP3r9MdT01z913u3hvIAvqbWayb6czsHOALd38v3bHUspPdvS9wFnB11DQbZ42BvsCv3b0PsAWYkKqdK9HXY1E79Z+Aae7+53THU5uin7WzgKFpDqWmnQQMi9qspwOnmdnv0xtSzXP3VdH7F8BzQP/0RlTjCoCChF+ozxISf0oo0ddT0YXJh4FF7v7LdMdTG8ysnZm1iaYPAM4EFqc1qBrm7je5e5a7ZwMjgdfd/ZI0h1WjzOzAqIMBUfPFt4BY96Zz9zXAZ2Z2dLTodCBlHSti8yhBM/sDMBhoa2YFwG3u/nB6o6pRJwGXAu9HbdYAN7v7jPSFVOM6AI+bWQahkvKMuzeI7oYNTHvguehh6I2Bp9z95fSGVCt+BEyLetwsBy5L1Y5j071SREQqpqYbEZGYU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGY+/8f90MGBJgeuwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature extraction together with data augmentation\n",
        "#Instantiating and freezing the VGG16 convolutional base"
      ],
      "metadata": {
        "id": "w-QwXQ7a3spF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False\n"
      ],
      "metadata": {
        "id": "DnsWuLMeFuTC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing the list of trainable weights before and after freezing"
      ],
      "metadata": {
        "id": "mKA1iUCJ3vJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkP10ReZF0S5",
        "outputId": "cdeb572f-e90d-4110-a984-cc108ad29a51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwQFlsQfIQRv",
        "outputId": "72a2e035-6686-49c6-cda7-97b37d13bcfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding a data augmentation stage and a classifier to the convolutional base"
      ],
      "metadata": {
        "id": "N5fBdzVu3ygP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.9)(x)\n",
        "x = layers.Dropout(0.6)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owfmcyFTIQ7T",
        "outputId": "0ad164cf-6f24-4312-ec0b-c54e7efca7c4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=6,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGPSNN1YIW7-",
        "outputId": "4065fbda-5020-4cb2-aebf-faa8293743e9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 7s 111ms/step - loss: 38.4525 - accuracy: 0.7790 - val_loss: 3.5605 - val_accuracy: 0.9680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model on the test set"
      ],
      "metadata": {
        "id": "vHpStYWY36qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCi74dJTIZRK",
        "outputId": "42e95a6f-8021-4a40-ea95-d0a9450b9fd8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 16ms/step - loss: 5.5635 - accuracy: 0.9560\n",
            "Test accuracy: 0.956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning a pretrained model"
      ],
      "metadata": {
        "id": "NVD5qCBT381G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "conv_base.summary()"
      ],
      "metadata": {
        "id": "RPpB9wX9IfWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74998cdd-beaa-4106-db15-698eecceb281"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Freezing all layers until the fourth from the last"
      ],
      "metadata": {
        "id": "-4_SDM7_3_SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    "
      ],
      "metadata": {
        "id": "yPUbgWmvIkTO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning the model"
      ],
      "metadata": {
        "id": "m3tw9dlw4BJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=6,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "DPmrzQs7Ios4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711e526c-d580-4b6a-b58a-9fb1c493c55f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 20s 103ms/step - loss: 2.3987 - accuracy: 0.9882 - val_loss: 7.2690 - val_accuracy: 0.9580\n",
            "Epoch 2/6\n",
            "157/157 [==============================] - 16s 100ms/step - loss: 2.2742 - accuracy: 0.9872 - val_loss: 7.3012 - val_accuracy: 0.9600\n",
            "Epoch 3/6\n",
            "157/157 [==============================] - 16s 100ms/step - loss: 2.0024 - accuracy: 0.9886 - val_loss: 7.2703 - val_accuracy: 0.9600\n",
            "Epoch 4/6\n",
            "157/157 [==============================] - 16s 101ms/step - loss: 2.0066 - accuracy: 0.9878 - val_loss: 7.2840 - val_accuracy: 0.9600\n",
            "Epoch 5/6\n",
            "157/157 [==============================] - 16s 102ms/step - loss: 2.2211 - accuracy: 0.9886 - val_loss: 7.2210 - val_accuracy: 0.9600\n",
            "Epoch 6/6\n",
            "157/157 [==============================] - 16s 101ms/step - loss: 1.8825 - accuracy: 0.9882 - val_loss: 7.2290 - val_accuracy: 0.9620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing tuned model in test test"
      ],
      "metadata": {
        "id": "nK1AOAsW23GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"fine_tuning.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "j4KDQtqKIsxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180905bf-aad8-4b71-bd83-0da2a4f5f208"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 17ms/step - loss: 8.6010 - accuracy: 0.9680\n",
            "Test accuracy: 0.968\n"
          ]
        }
      ]
    }
  ]
}